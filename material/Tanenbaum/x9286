
011
b

100
1C

100
3C

2C

101
110
111

001

101
a

a
1D

a

2D

a

3D

110
111

Figure 8-31. An omega switching network.

The wiring pattern of the omega network is often called the perfect shuffle,
since the mixing of the signals at each stage resembles a deck of cards being cut in
half and then mixed card-for-card. To see how the omega network works, suppose
that CPU 011 wants to read a word from memory module 110. The CPU sends a
READ message to switch 1D containing 110 in the Module field. The switch takes
the first (i.e., leftmost) bit of 110 and uses it for routing. A 0 routes to the upper
output and a 1 routes to the lower one. Since this bit is a 1, the message is routed
via the lower output to 2D.
All the second-stage switches, including 2D, use the second bit for routing.
This, too, is a 1, so the message is now forwarded via the lower output to 3D. Here
the third bit is tested and found to be a 0. Consequently, the message goes out on
the upper output and arrives at memory 110, as desired. The path followed by this
message is marked in Fig. 8-31 by the letter a.
As the message moves through the switching network, the bits at the left-hand
end of the module number are no longer needed. They can be put to good use by
recording the incoming line number there, so the reply can find its way back. For
path a, the incoming lines are 0 (upper input to 1D), 1 (lower input to 2D), and 1
(lower input to 3D), respectively. The reply is routed back using 011, only reading
it from right to left this time.
While all this is going on, CPU 001 wants to write a word to memory module
001. An analogous process happens here, with the message routed via the upper,
upper, and lower outputs, respectively, marked by the letter b. When it arrives, its

606

PARALLEL COMPUTER ARCHITECTURES

CHAP. 8

Module field reads 001, representing the path it took. Since these requests do not
use any of the same switches, lines, or memory modules, they can go in parallel.
Now consider what would happen if CPU 000 simultaneously wanted to access
memory module 000. Its request would come into conflict with CPU 001â€™s request
at switch 3A. One of them would have to wait. Unlike the crossbar switch, the
omega network is a blocking network. Not every set of requests can be processed
simultaneously. Conflicts can occur over the use of a wire or a switch, as well as
between requests to memory and replies from memory.
It is clearly desirable to spread the memory references uniformly across the
modules. One common technique is to use the low-order bits as the module number. Consider, for example, a byte-oriented address space for a computer that
mostly accesses 32-bit words. The 2 low-order bits will usually be 00, but the next
3 bits will be uniformly distributed. By using these 3 bits as the module number,
consecutively addressed words will be in consecutive modules. A memory system
in which consecutive words are in different modules is said to be interleaved.
Interleaved memories maximize parallelism because most memory references are
to consecutive addresses. It is also possible to design switching networks that are
nonblocking and that offer multiple paths from each CPU to each memory module,
to spread the traffic better.

8.3.4 NUMA Multiprocessors
It should be clear by now that single-bus UMA multiprocessors are generally
limited to no more than a few dozen CPUs and crossbar or switched multiprocessors need a lot of (expensive) hardware and are not that much bigger. To get to
more than 100 CPUs, something has to give. Usually, what gives is the idea that
all memory modules have the same access time. This concession leads to the idea
of NUMA (NonUniform Memory Access) multiprocessors. Like their UMA
cousins, they provide a single address space across all the CPUs, but unlike the
UMA machines, access to local memory modules is faster than access to remote
ones. Thus all UMA programs will run without change on NUMA machines, but
the performance will be worse than on a UMA machine at the same clock speed.
All NUMA machines have three key characteristics that together distinguish
them from other multiprocessors:
1. There is a single address space visible to all CPUs.
2. Access to remote memory done using LOAD and STORE instructions.
3. Access to remote memory is slower than access to local memory.
