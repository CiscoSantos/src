The great advance of the analytical engine was that it was general purpose. It
read instructions from punched cards and carried them out. Some instructions
commanded the machine to fetch two numbers from the store, bring them to the
mill, be operated on (e.g., added), and have the result sent back to the store. Other
instructions could test a number and conditionally branch depending on whether it
was positive or negative. By punching a different program on the input cards, it
was possible to have the analytical engine perform different computations, something not true of the difference engine.
Since the analytical engine was programmable in a simple assembly language,
it needed software. To produce this software, Babbage hired a young woman
named Augusta Ada Lovelace, who was the daughter of famed British poet Lord
Byron. Ada Lovelace was thus the world’s first computer programmer. The programming language Ada is named in her honor.
Unfortunately, like many modern designers, Babbage never quite got the hardware debugged. The problem was that he needed thousands upon thousands of
cogs and wheels and gears produced to a degree of precision that nineteenth-century technology was unable to provide. Nevertheless, his ideas were far ahead of
his time, and even today most modern computers have a structure very similar to
the analytical engine, so it is certainly fair to say that Babbage was the
(grand)father of the modern digital computer.
The next major development occurred in the late 1930s, when a German engineering student named Konrad Zuse built a series of automatic calculating machines
using electromagnetic relays. He was unable to get government funding after
WWII began because government bureaucrats expected to win the war so quickly
that the new machine would not be ready until after it was over. Zuse was unaware

16

INTRODUCTION

CHAP. 1

of Babbage’s work, and his machines were destroyed by the Allied bombing of
Berlin in 1944, so his work did not have any influence on subsequent machines.
Still, he was one of the pioneers of the field.
Slightly later, in the United States, two people also designed calculators, John
Atanasoff at Iowa State College and George Stibbitz at Bell Labs. Atanasoff’s machine was amazingly advanced for its time. It used binary arithmetic and had
capacitors for memory, which were periodically refreshed to keep the charge from
leaking out, a process he called ‘‘jogging the memory.’’ Modern dynamic memory
(DRAM) chips work the same way. Unfortunately the machine never really
became operational. In a way, Atanasoff was like Babbage: a visionary who was
ultimately defeated by the inadequate hardware technology of his time.
Stibbitz’ computer, although more primitive than Atanasoff’s, actually worked.
Stibbitz gave a public demonstration of it at a conference at Dartmouth College in
1940. Among those in the audience was John Mauchley, an unknown professor of
physics at the University of Pennsylvania. The computing world would hear more
about Prof. Mauchley later.
While Zuse, Stibbitz, and Atanasoff were designing automatic calculators, a
young man named Howard Aiken was grinding out tedious numerical calculations
by hand as part of his Ph.D. research at Harvard. After graduating, Aiken recognized the importance of being able to do calculations by machine. He went to the
library, discovered Babbage’s work, and decided to build out of relays the general-purpose computer that Babbage had failed to build out of toothed wheels.
Aiken’s first machine, the Mark I, was completed at Harvard in 1944. It had
72 words of 23 decimal digits each and had an instruction time of 6 sec. Input and
output used punched paper tape. By the time Aiken had completed its successor,
the Mark II, relay computers were obsolete. The electronic era had begun.

1.2.2 The First Generation—Vacuum Tubes (1945–1955)
The stimulus for the electronic computer was World War II. During the early
part of the war, German submarines were wreaking havoc on British ships. Commands were sent from the German admirals in Berlin to the submarines by radio,
which the British could, and did, intercept. The problem was that these messages
were encoded using a device called the ENIGMA, whose forerunner was designed
by amateur inventor and former U.S. president, Thomas Jefferson.
Early in the war, British intelligence managed to acquire an ENIGMA machine
from Polish Intelligence, which had stolen it from the Germans. However, to break
a coded message, a huge amount of computation was needed, and it was needed
very soon after the message was intercepted to be of any use. To decode these
messages, the British government set up a top secret laboratory that built an electronic computer called the COLOSSUS. The famous British mathematician Alan
Turing helped design this machine. The COLOSSUS was operational in 1943, but
since the British government kept virtually every aspect of the project classified as

SEC. 1.2

MILESTONES IN COMPUTER ARCHITECTURE

17

a military secret for 30 years, the COLOSSUS line was basically a dead end. It is
worth noting only because it was the world’s first electronic digital computer.
In addition to destroying Zuse’s machines and stimulating the construction of
the COLOSSUS, the war also affected computing in the United States. The army
needed range tables for aiming its heavy artillery. It produced these tables by hiring hundreds of women to crank them out using hand calculators (women were
thought to be more accurate than men). Nevertheless, the process was time consuming and errors often crept in.
John Mauchley, who knew of Atanasoff’s work as well as Stibbitz’, was aware
that the army was interested in mechanical calculators. Like many computer scientists after him, he put together a grant proposal asking the army for funding to
build an electronic computer. The proposal was accepted in 1943, and Mauchley
and his graduate student, J. Presper Eckert, proceeded to build an electronic computer, which they called the ENIAC (Electronic Numerical Integrator And
Computer). It consisted of 18,000 vacuum tubes and 1500 relays. The ENIAC
weighed 30 tons and consumed 140 kilowatts of power. Architecturally, the machine had 20 registers, each capable of holding a 10-digit decimal number. (A decimal register is very small memory that can hold one number up to some maximum
number of decimal digits, somewhat like the odometer that keeps track of how far
a car has traveled in its lifetime.) The ENIAC was programmed by setting up 6000
multiposition switches and connecting a multitude of sockets with a veritable forest of jumper cables.
The machine was not finished until 1946, too late to be of any use for its original purpose. However, since the war was over, Mauchley and Eckert were allowed
to organize a summer school to describe their work to their scientific colleagues.
That summer school was the beginning of an explosion of interest in building large
digital computers.
After that historic summer school, many other researchers set out to build electronic computers. The first one operational was the EDSAC (1949), built at the
University of Cambridge by Maurice Wilkes. Others included the JOHNNIAC at
the Rand Corporation, the ILLIAC at the University of Illinois, the MANIAC at
Los Alamos Laboratory, and the WEIZAC at the Weizmann Institute in Israel.
Eckert and Mauchley soon began working on a successor, the EDVAC (Electronic Discrete Variable Automatic Computer). However, that project was
fatally wounded when they left the University of Pennsylvania to form a startup
company, the Eckert-Mauchley Computer Corporation, in Philadelphia (Silicon
Valley had not yet been invented). After a series of mergers, this company became
the modern Unisys Corporation.
As a legal aside, Eckert and Mauchley filed for a patent claiming they invented
