data are in the local on-chip memory. Furthermore, many network-processor chips
also contain one or more specialized processors for doing pattern matching or
other critical operations. These processors are really small ASICs that are good at
one simple operation, such as looking up a destination address in the routing table.
All the components of the network processor communicate over one or more onchip, parallel buses that run at multigigabit/sec speeds.

580

PARALLEL COMPUTER ARCHITECTURES

CHAP. 8

Packet Processing
When a packet arrives, it goes through a number of processing stages, independent of whether the network processor has a parallel or pipeline organization.
Some network processors divide these steps into operations performed on incoming packets (either from a network line or from the system bus), called ingress
processing, and operations performed on outgoing packets, called egress processing. When this distinction is made, every packet goes first through ingress processing, then through egress processing. The boundary between ingress and egress
processing is flexible because some steps can be done in either part (e.g., collecting
traffic statistics).
Below we will discuss a potential ordering of the various steps, but note that
not all packets need all steps and that many other orderings are equally valid
1. Checksum verification. If the incoming packet is arriving from the
Ethernet, the CRC is recomputed so it can be compared with the one
in the packet to make sure there was no transmission error. If the
Ethernet CRC is correct or not present, the IP checksum is recomputed and compared to the one in the packet to make sure the IP packet was not damaged by a faulty bit in the senderâ€™s memory after the IP
checksum was computed there. If all checksums are correct, the
packet is accepted for further processing; otherwise, it is simply discarded.
2. Field extraction. The relevant header is parsed and key fields are
extracted. In an Ethernet switch, only the Ethernet header is examined, whereas in an IP router, it is the IP header that is inspected. The
key fields are stored in registers (parallel PPE organization) or SRAM
(pipeline organization).
3. Packet classification. The packet is classified according to a series
of programmable rules. The simplest classification is to distinguish
data packets from control packets, but usually much finer distinctions
are made.
4. Path selection. Most network processors have a special fast path optimized for handling plain old garden-variety data packets, with all
other packets being treated differently, often by the control processor.
Consequently, either the fast or the slow path has to be selected.
5. Destination network determination. IP packets contain a 32-bit
destination address. It is not possible (or even desirable) to have a 232
entry table to look up the destination of each IP packet, so the leftmost part of each IP address is the network number and the rest specifies a machine on that network. Network numbers can be of any

SEC. 8.2

COPROCESSORS

581

length, so determining the destination network number is nontrivial
and made worse by the fact that multiple matches are possible and the
longest one counts. Often a custom ASIC is used in this step.
6. Route lookup. Once the number of the destination network is
known, the outgoing line to use can be looked up in a table in the
SRAM. Again, a custom ASIC may be used in this step.
7. Fragmentation and reassembly. Programmers like to present large
payloads to the TCP layer to reduce the number of system calls needed, but TCP, IP, and Ethernet all have maximum sizes for the packets
they can handle. As a consequence of these limits, payloads and
packets may have to be fragmented at the sending side and the pieces
reassembled at the receiving side. These are tasks the network processor can perform.
8. Computation. Heavy-duty computation on the payload is sometimes
required, for example, data compression/decompression and encryption/decryption. These are tasks a network processor can perform.
9. Header management. Sometimes headers have to be added, removed, or have some of their fields modified. For example, the IP
header has a field that counts the number of hops the packet may yet
make before being discarded. Every time it is retransmitted, this field
must be decremented, something the network processor can do.
10. Queue management. Incoming and outgoing packets often have to
be queued while waiting their turn at being processed. Multimedia
applications may need a certain interpacket spacing in time to avoid
jitter. A firewall or router may need to distribute the incoming load
among multiple outgoing lines according to certain rules. All of these
tasks can be done by the network processor.
11. Checksum generation. Outgoing packets need to be checksummed.
The IP checksum can be generated by the network processor, but the
Ethernet CRC is generally computed by hardware.
12. Accounting. In some cases, accounting for packet traffic is needed,
especially when one network is forwarding traffic for other networks
as a commercial service. The network processor can do the accounting.
13. Statistics gathering. Finally, many organizations like to collect
statistics about their traffic. They want to know how many packets
came and and how many went out, at what times of day, and more.
The network processor is a good place to collect them.

582

PARALLEL COMPUTER ARCHITECTURES

CHAP. 8

Improving Performance
Performance is the name of the game for network processors. What can be
done to improve it? But before improving it, we have to define what performance
means. One metric is the number of packets forwarded per second. A second one
is the number of bytes forwarded per second. These are different measures, and a
scheme that works well with small packets may not work as well with large ones.
In particular, with small packets, improving the number of destination lookups per
second may help a lot, but with large packets it may not.
The most straightforward way to improve performance is to increase the speed
of the network processor clock. Of course, performance is not linear with clock
speed, since memory cycle time and other factors also influence it. Also, a faster
clock means more heat must be dissipated.
Introducing more PPEs and parallelism is often a winner, especially with an organization consisting of parallel PPEs. A deeper pipeline can also help, but only if
